{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "from typing import List, Optional, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ap, map検証 ここから"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _getArea(box):\n",
    "    return (box[2] - box[0] + 1) * (box[3] - box[1] + 1)\n",
    "\n",
    "def _boxesIntersect(boxA, boxB):\n",
    "    if boxA[0] > boxB[2]:\n",
    "        return False  # boxA is right of boxB\n",
    "    if boxB[0] > boxA[2]:\n",
    "        return False  # boxA is left of boxB\n",
    "    if boxA[3] < boxB[1]:\n",
    "        return False  # boxA is above boxB\n",
    "    if boxA[1] > boxB[3]:\n",
    "        return False  # boxA is below boxB\n",
    "    return True\n",
    "\n",
    "def _getIntersectionArea(boxA, boxB):\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    # intersection area\n",
    "    return (xB - xA + 1) * (yB - yA + 1)\n",
    "\n",
    "def _getUnionAreas(boxA, boxB, interArea=None):\n",
    "    area_A = _getArea(boxA)\n",
    "    area_B = _getArea(boxB)\n",
    "    if interArea is None:\n",
    "        interArea = _getIntersectionArea(boxA, boxB)\n",
    "    return float(area_A + area_B - interArea)\n",
    "\n",
    "# 11-point interpolated average precision\n",
    "def ElevenPointInterpolatedAP(rec, prec):\n",
    "    # def CalculateAveragePrecision2(rec, prec):\n",
    "    mrec = []\n",
    "    # mrec.append(0)\n",
    "    [mrec.append(e) for e in rec]\n",
    "    # mrec.append(1)\n",
    "    mpre = []\n",
    "    # mpre.append(0)\n",
    "    [mpre.append(e) for e in prec]\n",
    "    # mpre.append(0)\n",
    "    recallValues = np.linspace(0, 1, 11)\n",
    "    recallValues = list(recallValues[::-1])\n",
    "    rhoInterp = []\n",
    "    recallValid = []\n",
    "    # For each recallValues (0, 0.1, 0.2, ... , 1)\n",
    "    for r in recallValues:\n",
    "        # Obtain all recall values higher or equal than r\n",
    "        argGreaterRecalls = np.argwhere(mrec[:] >= r)\n",
    "        pmax = 0\n",
    "        # If there are recalls above r\n",
    "        if argGreaterRecalls.size != 0:\n",
    "            pmax = max(mpre[argGreaterRecalls.min():])\n",
    "        recallValid.append(r)\n",
    "        rhoInterp.append(pmax)\n",
    "    # By definition AP = sum(max(precision whose recall is above r))/11\n",
    "    ap = sum(rhoInterp) / 11\n",
    "    # Generating values for the plot\n",
    "    rvals = []\n",
    "    rvals.append(recallValid[0])\n",
    "    [rvals.append(e) for e in recallValid]\n",
    "    rvals.append(0)\n",
    "    pvals = []\n",
    "    pvals.append(0)\n",
    "    [pvals.append(e) for e in rhoInterp]\n",
    "    pvals.append(0)\n",
    "    # rhoInterp = rhoInterp[::-1]\n",
    "    cc = []\n",
    "    for i in range(len(rvals)):\n",
    "        p = (rvals[i], pvals[i - 1])\n",
    "        if p not in cc:\n",
    "            cc.append(p)\n",
    "        p = (rvals[i], pvals[i])\n",
    "        if p not in cc:\n",
    "            cc.append(p)\n",
    "    recallValues = [i[0] for i in cc]\n",
    "    rhoInterp = [i[1] for i in cc]\n",
    "    return [ap, rhoInterp, recallValues, None]\n",
    "\n",
    "def iou_score(bbox_det: tuple, bbox_gt: tuple) -> float:\n",
    "    \"\"\"calculate iou between two bbox\n",
    "    Args:\n",
    "        bbox_det(tuple): bbox of detected object. \n",
    "        bbox_gt(tuple): bbox of ground truth object\n",
    " \n",
    "    Returns:\n",
    "        iou(float): iou_score between two bbox\n",
    "\n",
    "    Note:\n",
    "\n",
    "    \"\"\"\n",
    "    # if boxes dont intersect\n",
    "    if _boxesIntersect(bbox_det, bbox_gt) is False:\n",
    "        return 0\n",
    "    interArea = _getIntersectionArea(bbox_det, bbox_gt)\n",
    "    union = _getUnionAreas(bbox_det, bbox_gt, interArea=interArea)\n",
    "    # intersection over union\n",
    "    iou = interArea / union\n",
    "    assert iou >= 0\n",
    "    return iou\n",
    "\n",
    "def ap_score(bboxes_det_per_class, bboxes_gt_per_class, IOUThreshold ,ap_only):\n",
    "    \"\"\"calculate average precision\n",
    "\n",
    "    Args:\n",
    "        bboxes_det_per_class(list): bbox of detected object per class.\n",
    "        bboxes_gt_per_class(list): bbox of ground truth object per class.\n",
    "        IOUThreshold(float): iou threshold\n",
    "        ap_only(bool): if True, return ap only. if False, return ap ,recall, precision, and so on.\n",
    "    Returns:\n",
    "        ap(float): average precision\n",
    "    \n",
    "    Note:\n",
    "        bboxes_det_per_class: [bbox_det_1, bbox_det_2, ...]\n",
    "        bboxes_gt_per_class: [bbox_gt_1, bbox_gt_2, ...]\n",
    "\n",
    "        #The elements of each bbox variable are as follows, each element basically corresponding to a property of the BoundingBox class of Object-Detection-Metrics.\n",
    "        https://github.com/rafaelpadilla/Object-Detection-Metrics/blob/master/lib/BoundingBox.py\n",
    "\n",
    "        ----\n",
    "        bbox_det_n(tuple): (imageName, classId, classConfidence, [xmin, ymin, xmax, ymax])\n",
    "        bbox_gt_n(tuple): (imageName, classId, 1.0, [xmin, ymin, xmax, ymax])\n",
    "        imageName(str): image name\n",
    "        classId(str): class id\n",
    "        classConfidence(float): class confidence\n",
    "        xmin(float): xmin\n",
    "        ymin(float): ymin\n",
    "        xmax(float): xmax\n",
    "        ymax(float): ymax\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    iouMax_list = []\n",
    "    gts = {}\n",
    "    npos = 0\n",
    "    for g in bboxes_gt_per_class:\n",
    "        npos += 1\n",
    "        gts[g[0]] = gts.get(g[0], []) + [g]\n",
    "\n",
    "    # sort detections by decreasing confidence\n",
    "    dects = sorted(bboxes_det_per_class, key=lambda conf: conf[2], reverse=True)\n",
    "    # print(\"dects: \", dects)\n",
    "    # create dictionary with amount of gts for each image\n",
    "    det = {key: np.zeros(len(gts[key])) for key in gts}\n",
    "    # print(dects)\n",
    "\n",
    "    print(\"Evaluating class: %s (%d detections)\" % (str(dects[0][1]), len(dects)))\n",
    "    # Loop through detections\n",
    "    TP = np.zeros(len(dects))\n",
    "    FP = np.zeros(len(dects))\n",
    "    for d in range(len(dects)):\n",
    "        # print('dect %s => %s' % (dects[d][0], dects[d][3],))\n",
    "        # Find ground truth image\n",
    "        gt = gts[dects[d][0]] if dects[d][0] in gts else []\n",
    "        iouMax = sys.float_info.min\n",
    "\n",
    "        for j in range(len(gt)):\n",
    "            iou = iou_score(dects[d][3], gt[j][3])\n",
    "            if iou > iouMax:\n",
    "                iouMax = iou\n",
    "                jmax = j\n",
    "                iouMax_list.append(iouMax)\n",
    "\n",
    "        # Assign detection as true positive/don't care/false positive\n",
    "        if iouMax >= IOUThreshold:\n",
    "            TP[d] = 1  # count as true positive\n",
    "            det[dects[d][0]][jmax] = 1  # flag as already 'seen'\n",
    "        else:\n",
    "            FP[d] = 1  # count as false positive\n",
    "\n",
    "    # compute precision, recall and average precision\n",
    "    acc_FP = np.cumsum(FP)\n",
    "    acc_TP = np.cumsum(TP)\n",
    "    rec = acc_TP / npos\n",
    "    prec = np.divide(acc_TP, (acc_FP + acc_TP))\n",
    "    # Depending on the method, call the right implementation\n",
    "    [ap_, mpre_, mrec_, _] = ElevenPointInterpolatedAP(rec, prec)\n",
    "    # if method == MethodAveragePrecision.EveryPointInterpolation:\n",
    "\n",
    "    if ap_only:\n",
    "        ap = {\n",
    "            'class': dects[0][1],\n",
    "            'AP': ap_\n",
    "            }\n",
    "        return ap\n",
    "    else:\n",
    "        ap = {\n",
    "            'class': dects[0][1],\n",
    "            'precision': prec,\n",
    "            'recall': rec,\n",
    "            'AP': ap_,\n",
    "            'interpolated precision': mpre_,\n",
    "            'interpolated recall': mrec_,\n",
    "            'total positives': npos,\n",
    "            'total TP': np.sum(TP),\n",
    "            'total FP': np.sum(FP)\n",
    "        }\n",
    "        return ap\n",
    "\n",
    "def map_score(bboxes_det, bboxes_gt, IOUThreshold) -> float:\n",
    "    \"\"\"calculate mean average precision\n",
    "    Args:\n",
    "        bboxes_det(list): bbox of detected object.\n",
    "        bboxes_gt(list): bbox of ground truth object\n",
    "        IOUThreshold(float): iou threshold\n",
    "\n",
    "    Returns:\n",
    "        map_score(float): mean average precision\n",
    "    \"\"\"\n",
    "    ap_list = []\n",
    "    class_list = []\n",
    "    #calculate ap\n",
    "    for bbox_det in bboxes_det:\n",
    "        if bbox_det[1] not in class_list:\n",
    "            class_list.append(bbox_det[1])\n",
    "\n",
    "    classes = sorted(class_list)\n",
    "    for class_id in classes:\n",
    "        bboxes_det_per_class = [detection_per_class for detection_per_class in bboxes_det if detection_per_class[1] == class_id]\n",
    "        bboxes_gt_per_class = [groundTruth_per_class for groundTruth_per_class in bboxes_gt if groundTruth_per_class[1] == class_id]\n",
    "        ap = ap_score(bboxes_det_per_class, bboxes_gt_per_class, IOUThreshold, ap_only=True)\n",
    "        # print(f'ap: {ap}')\n",
    "        ap_list.append(ap['AP'])\n",
    "    #calculate map\n",
    "    map = np.mean(ap_list)\n",
    "    return map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dummy bounding box\n",
    "image_num = 5 #number of images\n",
    "bbox_offset = 0 #検出用バウンディングボックスのオフセット\n",
    "IOUThreshold = 0.5 #IOU閾値\n",
    "ap_only = True #calc_ap関数で、APのみを出力するかどうかのトリガー\n",
    "\n",
    "bboxes_det = []\n",
    "bboxes_gt = []\n",
    "classes = []\n",
    "\n",
    "for image_name in range(image_num):\n",
    "    for ClassId in [0 ,32] :\n",
    "        for num in range(0, 1000, 100):\n",
    "            imageName = f'{image_name}'\n",
    "            classId = f'{ClassId}'\n",
    "\n",
    "            bbox_offset = random.randint(0, 100) #Offset of the bounding box(random) <- ハイパラ\n",
    "            # print(f'bbox_offset: {bbox_offset}')\n",
    "            \n",
    "\n",
    "            num_gt = num\n",
    "            num_det = num + bbox_offset\n",
    "            # print(f'image_name: {getImageName} , class_id: {getClassId} , num_gt: {num_gt}, num_det: {num_det}')\n",
    "\n",
    "            x1 = (1 * num_gt , 1 * num_det)\n",
    "            y1 = (1 * num_gt , 1 * num_det)\n",
    "            x2 = (1 * num_gt + 50 , 1 * num_det+ 50)\n",
    "            y2 = (1 * num_gt + 50 , 1 * num_det+ 50)\n",
    "\n",
    "\n",
    "            getAbsoluteBoundingBox_det = (x1[1], y1[1], x2[1], y2[1])\n",
    "            getAbsoluteBoundingBox_gt = (x1[0], y1[0], x2[0], y2[0])\n",
    "            \n",
    "            \n",
    "            getConfidence = random.random()\n",
    "\n",
    "            gt_info = [imageName, classId, 1, getAbsoluteBoundingBox_gt]\n",
    "            det_info = [imageName, classId, getConfidence ,getAbsoluteBoundingBox_det]\n",
    "\n",
    "            if classId not in classes:\n",
    "                classes.append(classId)\n",
    "\n",
    "            bboxes_det.append(det_info)\n",
    "            bboxes_gt.append(gt_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating class: 0 (50 detections)\n",
      "ap: {'class': '0', 'AP': 0.07389162561576355}\n",
      "Evaluating class: 32 (50 detections)\n",
      "ap: {'class': '32', 'AP': 0.08554322347425795}\n",
      "----------------------------------------------------\n",
      "Evaluating class: 0 (50 detections)\n",
      "Evaluating class: 32 (50 detections)\n",
      "map: 0.07632575757575757\n"
     ]
    }
   ],
   "source": [
    "#### test ###\n",
    "#calculate iou\n",
    "for i in range(len(bboxes_det)):\n",
    "    iou = iou_score(bboxes_det[i][3], bboxes_gt[i][3])\n",
    "    # print(f'iou: {iou}')\n",
    "\n",
    "#calculate ap\n",
    "classes = sorted(classes)\n",
    "for class_id in classes:\n",
    "    bboxes_det_per_class = [detection_per_class for detection_per_class in bboxes_det if detection_per_class[1] == class_id]\n",
    "    bboxes_gt_per_class = [groundTruth_per_class for groundTruth_per_class in bboxes_gt if groundTruth_per_class[1] == class_id]\n",
    "    ap = ap_score(bboxes_det_per_class, bboxes_gt_per_class, IOUThreshold, ap_only=True)\n",
    "    print(f'ap: {ap}')\n",
    "\n",
    "print('----------------------------------------------------')\n",
    "#calculate map\n",
    "map = map_score(bboxes_gt, bboxes_det, IOUThreshold)\n",
    "print(f'map: {map}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ここまで"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #calculate ap\n",
    "# classes = sorted(classes)\n",
    "# for class_id in classes:\n",
    "#     bboxes_gt = [groundTruth_per_class for groundTruth_per_class in groundTruths if groundTruth_per_class[1] == class_id]\n",
    "#     bboxes_det = [detection_per_class for detection_per_class in detections if detection_per_class[1] == class_id]\n",
    "#     ap = ap_score(bboxes_det, bboxes_gt, IOUThreshold, ap_only=True)\n",
    "#     print(f'ap: {ap}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #calculate iou\n",
    "# classes = sorted(classes)\n",
    "# for class_id in classes:\n",
    "#     # Get only detection of class c\n",
    "#     dects = []\n",
    "#     [dects.append(d) for d in detections if d[1] == class_id]\n",
    "#     # Get only ground truths of class c, use filename as key\n",
    "#     gts = {}\n",
    "#     npos = 0\n",
    "#     for g in groundTruths:\n",
    "#         if g[1] == class_id:\n",
    "#             npos += 1\n",
    "#             gts[g[0]] = gts.get(g[0], []) + [g]\n",
    "\n",
    "#     # sort detections by decreasing confidence\n",
    "#     dects = sorted(dects, key=lambda conf: conf[2], reverse=True)\n",
    "#     # create dictionary with amount of gts for each image\n",
    "#     det = {key: np.zeros(len(gts[key])) for key in gts}\n",
    "#     # print(dects)\n",
    "\n",
    "#     print(\"Evaluating class: %s (%d detections)\" % (str(class_id), len(dects)))\n",
    "#     # Loop through detections\n",
    "#     TP = np.zeros(len(dects))\n",
    "#     FP = np.zeros(len(dects))\n",
    "#     for d in range(len(dects)):\n",
    "#         # print('dect %s => %s' % (dects[d][0], dects[d][3],))\n",
    "#         # Find ground truth image\n",
    "#         gt = gts[dects[d][0]] if dects[d][0] in gts else []\n",
    "#         iouMax = sys.float_info.min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #calculate iou\n",
    "# classes = sorted(classes)\n",
    "# ap_score_list = []  # list containing metrics of each class\n",
    "# for class_id in classes:\n",
    "#     # Get only detection of class c\n",
    "#     dects = []\n",
    "#     [dects.append(d) for d in detections if d[1] == class_id]\n",
    "#     # Get only ground truths of class c, use filename as key\n",
    "#     gts = {}\n",
    "#     npos = 0\n",
    "#     for g in groundTruths:\n",
    "#         if g[1] == class_id:\n",
    "#             npos += 1\n",
    "#             gts[g[0]] = gts.get(g[0], []) + [g]\n",
    "\n",
    "#     # sort detections by decreasing confidence\n",
    "#     dects = sorted(dects, key=lambda conf: conf[2], reverse=True)\n",
    "#     # create dictionary with amount of gts for each image\n",
    "#     det = {key: np.zeros(len(gts[key])) for key in gts}\n",
    "\n",
    "#     print(\"Evaluating class: %s (%d detections)\" % (str(class_id), len(dects)))\n",
    "#     # Loop through detections\n",
    "#     TP = np.zeros(len(dects))\n",
    "#     FP = np.zeros(len(dects))\n",
    "#     for d in range(len(dects)):\n",
    "#         # print('dect %s => %s' % (dects[d][0], dects[d][3],))\n",
    "#         # Find ground truth image\n",
    "#         gt = gts[dects[d][0]] if dects[d][0] in gts else []\n",
    "#         iouMax = sys.float_info.min\n",
    "#         for j in range(len(gt)):\n",
    "#             # print('Ground truth gt => %s' % (gt[j][3],))\n",
    "#             iou = iou_score(dects[d][3], gt[j][3])\n",
    "#             # print('iou_output => %s' % (iou_output,))\n",
    "#             if iou > iouMax:\n",
    "#                 iouMax = iou\n",
    "#                 jmax = j\n",
    "#                 # print(iouMax)\n",
    "#                 iouMax_list.append(iouMax)\n",
    "#                 # print(f'img_name: {dects[d][0]} , class_id: {dects[d][1]} , confidence: {dects[d][2]} , iou: {iouMax}, jmax: {jmax}')\n",
    "#             # print(iou_output)\n",
    "#         # Assign detection as true positive/don't care/false positive\n",
    "#         if iouMax >= IOUThreshold:\n",
    "#             TP[d] = 1  # count as true positive\n",
    "#             det[dects[d][0]][jmax] = 1  # flag as already 'seen'\n",
    "#             # print(\"TP\")\n",
    "#         else:\n",
    "#             FP[d] = 1  # count as false positive\n",
    "#     # compute precision, recall and average precision\n",
    "\n",
    "#     ap = ap_score(class_id, TP, FP, npos, ap_only)\n",
    "\n",
    "\n",
    "    \n",
    "#     print(f'ap_info: {ap}')\n",
    "#     ap_score_list.append(ap)\n",
    "\n",
    "# map_score = calc_map(ap_score_list)\n",
    "\n",
    "# print('-----')\n",
    "# print(f'map_score: {map_score}')\n",
    "\n",
    "# # iouMax_list\n",
    "# # >>> [1.0, 1.0, ....., 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ret = []  # list containing metrics (precision, recall, average precision) of each class\n",
    "# # List with all ground truths (Ex: [imageName,class,confidence=1, (bb coordinates XYX2Y2)])\n",
    "# groundTruths = []\n",
    "# # List with all detections (Ex: [imageName,class,confidence,(bb coordinates XYX2Y2)])\n",
    "# detections = []\n",
    "# # Get all classes\n",
    "# classes = []\n",
    "# # Loop through all bounding boxes and separate them into GTs and detections\n",
    "# for bb in boundingboxes.getBoundingBoxes():\n",
    "#     # [imageName, class, confidence, (bb coordinates XYX2Y2)]\n",
    "#     if bb.getBBType() == BBType.GroundTruth:\n",
    "#         groundTruths.append([\n",
    "#             bb.getImageName(),\n",
    "#             bb.getClassId(), 1,\n",
    "#             bb.getAbsoluteBoundingBox(BBFormat.XYX2Y2)\n",
    "#         ])\n",
    "#     else:\n",
    "#         detections.append([\n",
    "#             bb.getImageName(),\n",
    "#             bb.getClassId(),\n",
    "#             bb.getConfidence(),\n",
    "#             bb.getAbsoluteBoundingBox(BBFormat.XYX2Y2)\n",
    "#         ])\n",
    "#     # get class\n",
    "#     if bb.getClassId() not in classes:\n",
    "#         classes.append(bb.getClassId())\n",
    "# classes = sorted(classes)\n",
    "\n",
    "# # Precision x Recall is obtained individually by each class\n",
    "# # Loop through by classes\n",
    "# for c in classes:\n",
    "#     # Get only detection of class c\n",
    "#     dects = []\n",
    "#     [dects.append(d) for d in detections if d[1] == c]\n",
    "#     # Get only ground truths of class c, use filename as key\n",
    "#     gts = {}\n",
    "#     npos = 0\n",
    "#     for g in groundTruths:\n",
    "#         if g[1] == c:\n",
    "#             npos += 1\n",
    "#             gts[g[0]] = gts.get(g[0], []) + [g]\n",
    "\n",
    "#     # sort detections by decreasing confidence\n",
    "#     dects = sorted(dects, key=lambda conf: conf[2], reverse=True)\n",
    "#     TP = np.zeros(len(dects))\n",
    "#     FP = np.zeros(len(dects))\n",
    "#     # create dictionary with amount of gts for each image\n",
    "#     det = {key: np.zeros(len(gts[key])) for key in gts}\n",
    "\n",
    "#     # print(\"Evaluating class: %s (%d detections)\" % (str(c), len(dects)))\n",
    "#     # Loop through detections\n",
    "#     for d in range(len(dects)):\n",
    "#         # print('dect %s => %s' % (dects[d][0], dects[d][3],))\n",
    "#         # Find ground truth image\n",
    "#         gt = gts[dects[d][0]] if dects[d][0] in gts else []\n",
    "#         iouMax = sys.float_info.min\n",
    "#         for j in range(len(gt)):\n",
    "#             # print('Ground truth gt => %s' % (gt[j][3],))\n",
    "#             iou = Evaluator.iou(dects[d][3], gt[j][3])\n",
    "#             if iou > iouMax:\n",
    "#                 iouMax = iou\n",
    "#                 jmax = j\n",
    "#         # Assign detection as true positive/don't care/false positive\n",
    "#         if iouMax >= IOUThreshold:\n",
    "#             if det[dects[d][0]][jmax] == 0:\n",
    "#                 TP[d] = 1  # count as true positive\n",
    "#                 det[dects[d][0]][jmax] = 1  # flag as already 'seen'\n",
    "#                 # print(\"TP\")\n",
    "#             else:\n",
    "#                 FP[d] = 1  # count as false positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Evaluator:\n",
    "#     def GetPascalVOCMetrics(self,\n",
    "#                             boundingboxes,\n",
    "#                             IOUThreshold=0.5,\n",
    "#                             method=MethodAveragePrecision.EveryPointInterpolation):\n",
    "#         \"\"\"Get the metrics used by the VOC Pascal 2012 challenge.\n",
    "#         Get\n",
    "#         Args:\n",
    "#             boundingboxes: Object of the class BoundingBoxes representing ground truth and detected\n",
    "#             bounding boxes;\n",
    "#             IOUThreshold: IOU threshold indicating which detections will be considered TP or FP\n",
    "#             (default value = 0.5);\n",
    "#             method (default = EveryPointInterpolation): It can be calculated as the implementation\n",
    "#             in the official PASCAL VOC toolkit (EveryPointInterpolation), or applying the 11-point\n",
    "#             interpolatio as described in the paper \"The PASCAL Visual Object Classes(VOC) Challenge\"\n",
    "#             or EveryPointInterpolation\"  (ElevenPointInterpolation);\n",
    "#         Returns:\n",
    "#             A list of dictionaries. Each dictionary contains information and metrics of each class.\n",
    "#             The keys of each dictionary are:\n",
    "#             dict['class']: class representing the current dictionary;\n",
    "#             dict['precision']: array with the precision values;\n",
    "#             dict['recall']: array with the recall values;\n",
    "#             dict['AP']: average precision;\n",
    "#             dict['interpolated precision']: interpolated precision values;\n",
    "#             dict['interpolated recall']: interpolated recall values;\n",
    "#             dict['total positives']: total number of ground truth positives;\n",
    "#             dict['total TP']: total number of True Positive detections;\n",
    "#             dict['total FP']: total number of False Positive detections;\n",
    "#         \"\"\"\n",
    "#         ret = []  # list containing metrics (precision, recall, average precision) of each class\n",
    "#         # List with all ground truths (Ex: [imageName,class,confidence=1, (bb coordinates XYX2Y2)])\n",
    "#         groundTruths = []\n",
    "#         # List with all detections (Ex: [imageName,class,confidence,(bb coordinates XYX2Y2)])\n",
    "#         detections = []\n",
    "#         # Get all classes\n",
    "#         classes = []\n",
    "#         # Loop through all bounding boxes and separate them into GTs and detections\n",
    "#         for bb in boundingboxes.getBoundingBoxes():\n",
    "#             # [imageName, class, confidence, (bb coordinates XYX2Y2)]\n",
    "#             if bb.getBBType() == BBType.GroundTruth:\n",
    "#                 groundTruths.append([\n",
    "#                     bb.getImageName(),\n",
    "#                     bb.getClassId(), 1,\n",
    "#                     bb.getAbsoluteBoundingBox(BBFormat.XYX2Y2)\n",
    "#                 ])\n",
    "#             else:\n",
    "#                 detections.append([\n",
    "#                     bb.getImageName(),\n",
    "#                     bb.getClassId(),\n",
    "#                     bb.getConfidence(),\n",
    "#                     bb.getAbsoluteBoundingBox(BBFormat.XYX2Y2)\n",
    "#                 ])\n",
    "#             # get class\n",
    "#             if bb.getClassId() not in classes:\n",
    "#                 classes.append(bb.getClassId())\n",
    "#         classes = sorted(classes)\n",
    "#         # Precision x Recall is obtained individually by each class\n",
    "#         # Loop through by classes\n",
    "#         for c in classes:\n",
    "#             # Get only detection of class c\n",
    "#             dects = []\n",
    "#             [dects.append(d) for d in detections if d[1] == c]\n",
    "#             # Get only ground truths of class c, use filename as key\n",
    "#             gts = {}\n",
    "#             npos = 0\n",
    "#             for g in groundTruths:\n",
    "#                 if g[1] == c:\n",
    "#                     npos += 1\n",
    "#                     gts[g[0]] = gts.get(g[0], []) + [g]\n",
    "\n",
    "#             # sort detections by decreasing confidence\n",
    "#             dects = sorted(dects, key=lambda conf: conf[2], reverse=True)\n",
    "#             TP = np.zeros(len(dects))\n",
    "#             FP = np.zeros(len(dects))\n",
    "#             # create dictionary with amount of gts for each image\n",
    "#             det = {key: np.zeros(len(gts[key])) for key in gts}\n",
    "\n",
    "#             # print(\"Evaluating class: %s (%d detections)\" % (str(c), len(dects)))\n",
    "#             # Loop through detections\n",
    "#             for d in range(len(dects)):\n",
    "#                 # print('dect %s => %s' % (dects[d][0], dects[d][3],))\n",
    "#                 # Find ground truth image\n",
    "#                 gt = gts[dects[d][0]] if dects[d][0] in gts else []\n",
    "#                 iouMax = sys.float_info.min\n",
    "#                 for j in range(len(gt)):\n",
    "#                     # print('Ground truth gt => %s' % (gt[j][3],))\n",
    "#                     iou = Evaluator.iou(dects[d][3], gt[j][3])\n",
    "#                     if iou > iouMax:\n",
    "#                         iouMax = iou\n",
    "#                         jmax = j\n",
    "#                 # Assign detection as true positive/don't care/false positive\n",
    "#                 if iouMax >= IOUThreshold:\n",
    "#                     if det[dects[d][0]][jmax] == 0:\n",
    "#                         TP[d] = 1  # count as true positive\n",
    "#                         det[dects[d][0]][jmax] = 1  # flag as already 'seen'\n",
    "#                         # print(\"TP\")\n",
    "#                     else:\n",
    "#                         FP[d] = 1  # count as false positive\n",
    "#                         # print(\"FP\")\n",
    "#                 # - A detected \"cat\" is overlaped with a GT \"cat\" with IOU >= IOUThreshold.\n",
    "#                 else:\n",
    "#                     FP[d] = 1  # count as false positive\n",
    "#                     # print(\"FP\")\n",
    "#             # compute precision, recall and average precision\n",
    "#             acc_FP = np.cumsum(FP)\n",
    "#             acc_TP = np.cumsum(TP)\n",
    "#             rec = acc_TP / npos\n",
    "#             prec = np.divide(acc_TP, (acc_FP + acc_TP))\n",
    "#             # Depending on the method, call the right implementation\n",
    "#             if method == MethodAveragePrecision.EveryPointInterpolation:\n",
    "#                 [ap, mpre, mrec, ii] = Evaluator.CalculateAveragePrecision(rec, prec)\n",
    "#             else:\n",
    "#                 [ap, mpre, mrec, _] = Evaluator.ElevenPointInterpolatedAP(rec, prec)\n",
    "#             # add class result in the dictionary to be returned\n",
    "#             r = {\n",
    "#                 'class': c,\n",
    "#                 'precision': prec,\n",
    "#                 'recall': rec,\n",
    "#                 'AP': ap,\n",
    "#                 'interpolated precision': mpre,\n",
    "#                 'interpolated recall': mrec,\n",
    "#                 'total positives': npos,\n",
    "#                 'total TP': np.sum(TP),\n",
    "#                 'total FP': np.sum(FP)\n",
    "#             }\n",
    "#             ret.append(r)\n",
    "#         return ret\n",
    "\n",
    "#     def PlotPrecisionRecallCurve(self,\n",
    "#                                  boundingBoxes,\n",
    "#                                  IOUThreshold=0.5,\n",
    "#                                  method=MethodAveragePrecision.EveryPointInterpolation,\n",
    "#                                  showAP=False,\n",
    "#                                  showInterpolatedPrecision=False,\n",
    "#                                  savePath=None,\n",
    "#                                  showGraphic=True):\n",
    "#         \"\"\"PlotPrecisionRecallCurve\n",
    "#         Plot the Precision x Recall curve for a given class.\n",
    "#         Args:\n",
    "#             boundingBoxes: Object of the class BoundingBoxes representing ground truth and detected\n",
    "#             bounding boxes;\n",
    "#             IOUThreshold (optional): IOU threshold indicating which detections will be considered\n",
    "#             TP or FP (default value = 0.5);\n",
    "#             method (default = EveryPointInterpolation): It can be calculated as the implementation\n",
    "#             in the official PASCAL VOC toolkit (EveryPointInterpolation), or applying the 11-point\n",
    "#             interpolatio as described in the paper \"The PASCAL Visual Object Classes(VOC) Challenge\"\n",
    "#             or EveryPointInterpolation\"  (ElevenPointInterpolation).\n",
    "#             showAP (optional): if True, the average precision value will be shown in the title of\n",
    "#             the graph (default = False);\n",
    "#             showInterpolatedPrecision (optional): if True, it will show in the plot the interpolated\n",
    "#              precision (default = False);\n",
    "#             savePath (optional): if informed, the plot will be saved as an image in this path\n",
    "#             (ex: /home/mywork/ap.png) (default = None);\n",
    "#             showGraphic (optional): if True, the plot will be shown (default = True)\n",
    "#         Returns:\n",
    "#             A list of dictionaries. Each dictionary contains information and metrics of each class.\n",
    "#             The keys of each dictionary are:\n",
    "#             dict['class']: class representing the current dictionary;\n",
    "#             dict['precision']: array with the precision values;\n",
    "#             dict['recall']: array with the recall values;\n",
    "#             dict['AP']: average precision;\n",
    "#             dict['interpolated precision']: interpolated precision values;\n",
    "#             dict['interpolated recall']: interpolated recall values;\n",
    "#             dict['total positives']: total number of ground truth positives;\n",
    "#             dict['total TP']: total number of True Positive detections;\n",
    "#             dict['total FP']: total number of False Negative detections;\n",
    "#         \"\"\"\n",
    "#         results = self.GetPascalVOCMetrics(boundingBoxes, IOUThreshold, method)\n",
    "#         result = None\n",
    "#         # Each resut represents a class\n",
    "#         for result in results:\n",
    "#             if result is None:\n",
    "#                 raise IOError('Error: Class %d could not be found.' % classId)\n",
    "\n",
    "#             classId = result['class']\n",
    "#             precision = result['precision']\n",
    "#             recall = result['recall']\n",
    "#             average_precision = result['AP']\n",
    "#             mpre = result['interpolated precision']\n",
    "#             mrec = result['interpolated recall']\n",
    "#             npos = result['total positives']\n",
    "#             total_tp = result['total TP']\n",
    "#             total_fp = result['total FP']\n",
    "\n",
    "#             plt.close()\n",
    "#             if showInterpolatedPrecision:\n",
    "#                 if method == MethodAveragePrecision.EveryPointInterpolation:\n",
    "#                     plt.plot(mrec, mpre, '--r', label='Interpolated precision (every point)')\n",
    "#                 elif method == MethodAveragePrecision.ElevenPointInterpolation:\n",
    "#                     # Uncomment the line below if you want to plot the area\n",
    "#                     # plt.plot(mrec, mpre, 'or', label='11-point interpolated precision')\n",
    "#                     # Remove duplicates, getting only the highest precision of each recall value\n",
    "#                     nrec = []\n",
    "#                     nprec = []\n",
    "#                     for idx in range(len(mrec)):\n",
    "#                         r = mrec[idx]\n",
    "#                         if r not in nrec:\n",
    "#                             idxEq = np.argwhere(mrec == r)\n",
    "#                             nrec.append(r)\n",
    "#                             nprec.append(max([mpre[int(id)] for id in idxEq]))\n",
    "#                     plt.plot(nrec, nprec, 'or', label='11-point interpolated precision')\n",
    "#             plt.plot(recall, precision, label='Precision')\n",
    "#             plt.xlabel('recall')\n",
    "#             plt.ylabel('precision')\n",
    "#             if showAP:\n",
    "#                 ap_str = \"{0:.2f}%\".format(average_precision * 100)\n",
    "#                 # ap_str = \"{0:.4f}%\".format(average_precision * 100)\n",
    "#                 plt.title('Precision x Recall curve \\nClass: %s, AP: %s' % (str(classId), ap_str))\n",
    "#             else:\n",
    "#                 plt.title('Precision x Recall curve \\nClass: %s' % str(classId))\n",
    "#             plt.legend(shadow=True)\n",
    "#             plt.grid()\n",
    "#             ############################################################\n",
    "#             # Uncomment the following block to create plot with points #\n",
    "#             ############################################################\n",
    "#             # plt.plot(recall, precision, 'bo')\n",
    "#             # labels = ['R', 'Y', 'J', 'A', 'U', 'C', 'M', 'F', 'D', 'B', 'H', 'P', 'E', 'X', 'N', 'T',\n",
    "#             # 'K', 'Q', 'V', 'I', 'L', 'S', 'G', 'O']\n",
    "#             # dicPosition = {}\n",
    "#             # dicPosition['left_zero'] = (-30,0)\n",
    "#             # dicPosition['left_zero_slight'] = (-30,-10)\n",
    "#             # dicPosition['right_zero'] = (30,0)\n",
    "#             # dicPosition['left_up'] = (-30,20)\n",
    "#             # dicPosition['left_down'] = (-30,-25)\n",
    "#             # dicPosition['right_up'] = (20,20)\n",
    "#             # dicPosition['right_down'] = (20,-20)\n",
    "#             # dicPosition['up_zero'] = (0,30)\n",
    "#             # dicPosition['up_right'] = (0,30)\n",
    "#             # dicPosition['left_zero_long'] = (-60,-2)\n",
    "#             # dicPosition['down_zero'] = (-2,-30)\n",
    "#             # vecPositions = [\n",
    "#             #     dicPosition['left_down'],\n",
    "#             #     dicPosition['left_zero'],\n",
    "#             #     dicPosition['right_zero'],\n",
    "#             #     dicPosition['right_zero'],  #'R', 'Y', 'J', 'A',\n",
    "#             #     dicPosition['left_up'],\n",
    "#             #     dicPosition['left_up'],\n",
    "#             #     dicPosition['right_up'],\n",
    "#             #     dicPosition['left_up'],  # 'U', 'C', 'M', 'F',\n",
    "#             #     dicPosition['left_zero'],\n",
    "#             #     dicPosition['right_up'],\n",
    "#             #     dicPosition['right_down'],\n",
    "#             #     dicPosition['down_zero'],  #'D', 'B', 'H', 'P'\n",
    "#             #     dicPosition['left_up'],\n",
    "#             #     dicPosition['up_zero'],\n",
    "#             #     dicPosition['right_up'],\n",
    "#             #     dicPosition['left_up'],  # 'E', 'X', 'N', 'T',\n",
    "#             #     dicPosition['left_zero'],\n",
    "#             #     dicPosition['right_zero'],\n",
    "#             #     dicPosition['left_zero_long'],\n",
    "#             #     dicPosition['left_zero_slight'],  # 'K', 'Q', 'V', 'I',\n",
    "#             #     dicPosition['right_down'],\n",
    "#             #     dicPosition['left_down'],\n",
    "#             #     dicPosition['right_up'],\n",
    "#             #     dicPosition['down_zero']\n",
    "#             # ]  # 'L', 'S', 'G', 'O'\n",
    "#             # for idx in range(len(labels)):\n",
    "#             #     box = dict(boxstyle='round,pad=.5',facecolor='yellow',alpha=0.5)\n",
    "#             #     plt.annotate(labels[idx],\n",
    "#             #                 xy=(recall[idx],precision[idx]), xycoords='data',\n",
    "#             #                 xytext=vecPositions[idx], textcoords='offset points',\n",
    "#             #                 arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3\"),\n",
    "#             #                 bbox=box)\n",
    "#             if savePath is not None:\n",
    "#                 plt.savefig(os.path.join(savePath, str(classId) + '.png'))\n",
    "#             if showGraphic is True:\n",
    "#                 plt.show()\n",
    "#                 # plt.waitforbuttonpress()\n",
    "#                 plt.pause(0.05)\n",
    "#         return results\n",
    "\n",
    "#     # @staticmethod\n",
    "#     # def CalculateAveragePrecision(rec, prec):\n",
    "#     #     mrec = []\n",
    "#     #     mrec.append(0)\n",
    "#     #     [mrec.append(e) for e in rec]\n",
    "#     #     mrec.append(1)\n",
    "#     #     mpre = []\n",
    "#     #     mpre.append(0)\n",
    "#     #     [mpre.append(e) for e in prec]\n",
    "#     #     mpre.append(0)\n",
    "#     #     for i in range(len(mpre) - 1, 0, -1):\n",
    "#     #         mpre[i - 1] = max(mpre[i - 1], mpre[i])\n",
    "#     #     ii = []\n",
    "#     #     for i in range(len(mrec) - 1):\n",
    "#     #         if mrec[1+i] != mrec[i]:\n",
    "#     #             ii.append(i + 1)\n",
    "#     #     ap = 0\n",
    "#     #     for i in ii:\n",
    "#     #         ap = ap + np.sum((mrec[i] - mrec[i - 1]) * mpre[i])\n",
    "#     #     # return [ap, mpre[1:len(mpre)-1], mrec[1:len(mpre)-1], ii]\n",
    "#     #     return [ap, mpre[0:len(mpre) - 1], mrec[0:len(mpre) - 1], ii]\n",
    "\n",
    "#     @staticmethod\n",
    "#     # 11-point interpolated average precision\n",
    "#     # def ElevenPointInterpolatedAP(rec, prec):\n",
    "#     #     # def CalculateAveragePrecision2(rec, prec):\n",
    "#     #     mrec = []\n",
    "#     #     # mrec.append(0)\n",
    "#     #     [mrec.append(e) for e in rec]\n",
    "#     #     # mrec.append(1)\n",
    "#     #     mpre = []\n",
    "#     #     # mpre.append(0)\n",
    "#     #     [mpre.append(e) for e in prec]\n",
    "#     #     # mpre.append(0)\n",
    "#     #     recallValues = np.linspace(0, 1, 11)\n",
    "#     #     recallValues = list(recallValues[::-1])\n",
    "#     #     rhoInterp = []\n",
    "#     #     recallValid = []\n",
    "#     #     # For each recallValues (0, 0.1, 0.2, ... , 1)\n",
    "#     #     for r in recallValues:\n",
    "#     #         # Obtain all recall values higher or equal than r\n",
    "#     #         argGreaterRecalls = np.argwhere(mrec[:] >= r)\n",
    "#     #         pmax = 0\n",
    "#     #         # If there are recalls above r\n",
    "#     #         if argGreaterRecalls.size != 0:\n",
    "#     #             pmax = max(mpre[argGreaterRecalls.min():])\n",
    "#     #         recallValid.append(r)\n",
    "#     #         rhoInterp.append(pmax)\n",
    "#     #     # By definition AP = sum(max(precision whose recall is above r))/11\n",
    "#     #     ap = sum(rhoInterp) / 11\n",
    "#     #     # Generating values for the plot\n",
    "#     #     rvals = []\n",
    "#     #     rvals.append(recallValid[0])\n",
    "#     #     [rvals.append(e) for e in recallValid]\n",
    "#     #     rvals.append(0)\n",
    "#     #     pvals = []\n",
    "#     #     pvals.append(0)\n",
    "#     #     [pvals.append(e) for e in rhoInterp]\n",
    "#     #     pvals.append(0)\n",
    "#     #     # rhoInterp = rhoInterp[::-1]\n",
    "#     #     cc = []\n",
    "#     #     for i in range(len(rvals)):\n",
    "#     #         p = (rvals[i], pvals[i - 1])\n",
    "#     #         if p not in cc:\n",
    "#     #             cc.append(p)\n",
    "#     #         p = (rvals[i], pvals[i])\n",
    "#     #         if p not in cc:\n",
    "#     #             cc.append(p)\n",
    "#     #     recallValues = [i[0] for i in cc]\n",
    "#     #     rhoInterp = [i[1] for i in cc]\n",
    "#     #     return [ap, rhoInterp, recallValues, None]\n",
    "\n",
    "#     # For each detections, calculate IOU with reference\n",
    "#     @staticmethod\n",
    "#     def _getAllIOUs(reference, detections):\n",
    "#         ret = []\n",
    "#         bbReference = reference.getAbsoluteBoundingBox(BBFormat.XYX2Y2)\n",
    "#         # img = np.zeros((200,200,3), np.uint8)\n",
    "#         for d in detections:\n",
    "#             bb = d.getAbsoluteBoundingBox(BBFormat.XYX2Y2)\n",
    "#             iou = Evaluator.iou(bbReference, bb)\n",
    "#             # Show blank image with the bounding boxes\n",
    "#             # img = add_bb_into_image(img, d, color=(255,0,0), thickness=2, label=None)\n",
    "#             # img = add_bb_into_image(img, reference, color=(0,255,0), thickness=2, label=None)\n",
    "#             ret.append((iou, reference, d))  # iou, reference, detection\n",
    "#         # cv2.imshow(\"comparing\",img)\n",
    "#         # cv2.waitKey(0)\n",
    "#         # cv2.destroyWindow(\"comparing\")\n",
    "#         return sorted(ret, key=lambda i: i[0], reverse=True)  # sort by iou (from highest to lowest)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def iou(boxA, boxB):\n",
    "#         # if boxes dont intersect\n",
    "#         if Evaluator._boxesIntersect(boxA, boxB) is False:\n",
    "#             return 0\n",
    "#         interArea = Evaluator._getIntersectionArea(boxA, boxB)\n",
    "#         union = Evaluator._getUnionAreas(boxA, boxB, interArea=interArea)\n",
    "#         # intersection over union\n",
    "#         iou = interArea / union\n",
    "#         assert iou >= 0\n",
    "#         return iou\n",
    "\n",
    "#     # boxA = (Ax1,Ay1,Ax2,Ay2)\n",
    "#     # boxB = (Bx1,By1,Bx2,By2)\n",
    "#     @staticmethod\n",
    "#     def _boxesIntersect(boxA, boxB):\n",
    "#         if boxA[0] > boxB[2]:\n",
    "#             return False  # boxA is right of boxB\n",
    "#         if boxB[0] > boxA[2]:\n",
    "#             return False  # boxA is left of boxB\n",
    "#         if boxA[3] < boxB[1]:\n",
    "#             return False  # boxA is above boxB\n",
    "#         if boxA[1] > boxB[3]:\n",
    "#             return False  # boxA is below boxB\n",
    "#         return True\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _getIntersectionArea(boxA, boxB):\n",
    "#         xA = max(boxA[0], boxB[0])\n",
    "#         yA = max(boxA[1], boxB[1])\n",
    "#         xB = min(boxA[2], boxB[2])\n",
    "#         yB = min(boxA[3], boxB[3])\n",
    "#         # intersection area\n",
    "#         return (xB - xA + 1) * (yB - yA + 1)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _getUnionAreas(boxA, boxB, interArea=None):\n",
    "#         area_A = Evaluator._getArea(boxA)\n",
    "#         area_B = Evaluator._getArea(boxB)\n",
    "#         if interArea is None:\n",
    "#             interArea = Evaluator._getIntersectionArea(boxA, boxB)\n",
    "#         return float(area_A + area_B - interArea)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _getArea(box):\n",
    "#         return (box[2] - box[0] + 1) * (box[3] - box[1] + 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base_atom')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47bcc98a91e0639070087bf2bbd0f353a7498108652c8107efb5221696e92166"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
